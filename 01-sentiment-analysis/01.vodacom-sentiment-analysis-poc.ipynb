{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fded102b",
   "metadata": {},
   "source": [
    "# NPS verbatim sentiment analysis using Amazon Bedrock\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8b2cf",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this notebook, you are going to ingest a csv file for jNPS data from an Amazon S3 bucket, run the topic extraction and sentiment analysis on the data in the NPS verbatim column, and finally export the data back into an Amazon S3 bucket for further analysis.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "![](../Images/Heartbeat-POC-Architecture.png)\n",
    "\n",
    "In this architecture:\n",
    "\n",
    "1. A raw NPS csv file is loaded\n",
    "1. A foundation model processes the NPS verbatim data\n",
    "1. Model returns a response with the sentiment analysis against the topics mentioned in the NPS verbatim column.\n",
    "\n",
    "### Use case\n",
    "\n",
    "The use case here is NPS verbatim analysis in order to improve customer experience and operational effectiveness.\n",
    "This approach can also be used to analyze call transcripts, chat transcripts, journey events to create journey summaries etc.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "This approach can be used when the input text or file fits within the model context length. If the input text including the prompts exceed the context window size of the model, a retrieval augmented approach could be applied for topic identification, followed by sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf6ce4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e8b08d-f761-45ab-b20a-73867edb584e",
   "metadata": {},
   "source": [
    "### Install relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed821d51-1394-49d7-8db2-efd0fb2c34ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall --quiet\\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"botocore>=1.31.57\"\\\n",
    "    \"awswrangler\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f3bd1-dd34-4076-8265-bdf88313bdda",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96058f6-869a-4333-8b3c-f067965409ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ae82c8-3e2b-4788-98f7-902f55574a2c",
   "metadata": {},
   "source": [
    "### Initiate Amazon Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a11a4a-e8c3-42ed-be42-cd787c06c6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: MIT-0\n",
    "\"\"\"Helper utilities for working with Amazon Bedrock from Python notebooks\"\"\"\n",
    "# Python Built-Ins:\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "\n",
    "def get_bedrock_client(\n",
    "    assumed_role: Optional[str] = None,\n",
    "    region: Optional[str] = None,\n",
    "    runtime: Optional[bool] = True,\n",
    "):\n",
    "    \"\"\"Create a boto3 client for Amazon Bedrock, with optional configuration overrides\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    assumed_role :\n",
    "        Optional ARN of an AWS IAM role to assume for calling the Bedrock service. If not\n",
    "        specified, the current active credentials will be used.\n",
    "    region :\n",
    "        Optional name of the AWS Region in which the service should be called (e.g. \"us-east-1\").\n",
    "        If not specified, AWS_REGION or AWS_DEFAULT_REGION environment variable will be used.\n",
    "    runtime :\n",
    "        Optional choice of getting different client to perform operations with the Amazon Bedrock service.\n",
    "    \"\"\"\n",
    "    if region is None:\n",
    "        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
    "    else:\n",
    "        target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}\")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        response = sts.assume_role(\n",
    "            RoleArn=str(assumed_role),\n",
    "            RoleSessionName=\"langchain-llm-1\"\n",
    "        )\n",
    "        print(\" ... successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    bedrock_client = session.client(\n",
    "        service_name=service_name,\n",
    "        config=retry_config,\n",
    "        **client_kwargs\n",
    "    )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b065d0-322e-4480-bb55-df652e45c598",
   "metadata": {},
   "source": [
    "### Initiate Amazon Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66edf151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342796d0",
   "metadata": {},
   "source": [
    "## Calling the Amazon Bedrock API\n",
    " \n",
    "To learn detail of API request to Amazon Bedrock, this notebook introduces how to create API request and send the request via Boto3 rather than relying on langchain, which gives simpler API by wrapping Boto3 operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4d9ee",
   "metadata": {},
   "source": [
    "### Request Syntax of InvokeModel in Boto3\n",
    "\n",
    "\n",
    "We use `InvokeModel` API for sending request to a foundation model. Here is an example of API request for sending text to Anthropic Claude. Inference parameters in `textGenerationConfig` depends on the model that you are about to use. Inference paramerters of Anthropic Claude are:\n",
    "\n",
    "- **temperature** tunes the degree of randomness in generation. Lower temperatures mean less random generations.\n",
    "- **top_p** less than one keeps only the smallest set of most probable tokens with probabilities that add up to top_p or higher for generation.\n",
    "- **top_k** can be used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.\n",
    "- **max_tokens_to_sample** is maximum number of tokens to generate. Responses are not guaranteed to fill up to the maximum desired length.\n",
    "- **stop_sequences** are sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\n",
    "\n",
    "```python\n",
    "response = bedrock.invoke_model(body=\n",
    "                                {\"prompt\":\"this is where you place your input text\",\n",
    "                                 \"max_tokens_to_sample\":4096,\n",
    "                                 \"temperature\":0.5,\n",
    "                                 \"top_k\":250,\n",
    "                                 \"top_p\":0.5,\n",
    "                                 \"stop_sequences\":[]\n",
    "                                },\n",
    "                                modelId=\"anthropic.claude-v2\", \n",
    "                                accept=accept, \n",
    "                                contentType=contentType)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86df2f1-7397-44c4-b8a2-37e26e127031",
   "metadata": {},
   "source": [
    "### Load and explore the verbatim file\n",
    "\n",
    "⚠️ ⚠️ ⚠️ Please replace the below `bucket` and `key` variables below with the S3 bucket and prefix from your account where the jNPS file is stored ⚠️ ⚠️ ⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67fb6078-0b85-42de-844f-b8849976e2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S3 location\n",
    "bucket = 'vodacom-nps-poc-ajay'\n",
    "key = 'raw-data/September2023/Buy_SetUp.csv'\n",
    "\n",
    "# Read CSV using awswrangler \n",
    "df = wr.s3.read_csv(path=[f's3://{bucket}/{key}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c5f2c-9940-4634-90ca-7c49be3e1394",
   "metadata": {},
   "source": [
    "#### Explore the NPS verbatims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e558858-41aa-43fa-8d9f-4ae498c79806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if not pd.isnull(row['VERBATIM']):\n",
    "        print(f\"Row {index} : {row['VERBATIM']}\")\n",
    "        if index>50:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1894798-a313-4600-be8e-735ec0ac2255",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define a function to construct the prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d15ad0-2206-4aff-8ecc-49977bc9fcfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt(text):\n",
    "    prompt = \"\"\"Human: ‘The text below is a verbatim response to an NPS survey question -  \n",
    "                \n",
    "                \"Is there anything else you would like to share with us about your experience with Vodacom?\"\n",
    "                \n",
    "                Pick the topics mentioned in the text from a reference list of topics provided below. For each topic, respond with the sentiment expressed against that topic.\n",
    "\n",
    "                Text:\"\"\"+text+\"\"\"\n",
    "\n",
    "                List of Topics:\n",
    "\n",
    "                Change Account Details, \n",
    "                MSISDN change,\n",
    "                proof of usage,\n",
    "                Transfer of Ownership, \n",
    "                Account  Payment, \n",
    "                Account - Payment,\n",
    "                Billing Enquiry,\n",
    "                Call Barring,\n",
    "                Itemised Billing,\n",
    "                Payment Arrangement,\n",
    "                Car phone,\n",
    "                competitors,\n",
    "                Emails,\n",
    "                Vodacom,\n",
    "                Cancellation Enquiry,\n",
    "                MNP Port Enquiry,\n",
    "                PIN / PUK Enquiry,\n",
    "                Customer Care enquiry,\n",
    "                Customer's Feeling,\n",
    "                abusive call,\n",
    "                abusive text,\n",
    "                abusive txt,\n",
    "                Blacklist/Unblacklist Device,\n",
    "                Delivery Enquiry,\n",
    "                Handset Enquiry,\n",
    "                harassing,\n",
    "                harassment,\n",
    "                insurance,\n",
    "                malicious,\n",
    "                nuisance,\n",
    "                proof of purchase,\n",
    "                return,\n",
    "                stolen,\n",
    "                unwanted,\n",
    "                Upgrade Enquiry,\n",
    "                Vodacom Repair - Complaint,\n",
    "                General Network,\n",
    "                admin fee,\n",
    "                Authentication,\n",
    "                equest for Credit Refund,\n",
    "                Fraud,\n",
    "                Proof of Payment,\n",
    "                Charge Dispute,\n",
    "                Data Bundle Enquiry,\n",
    "                Deal Match,\n",
    "                discount,\n",
    "                Tariff Enquiry,\n",
    "                Tariff Enquiry/Free change,\n",
    "                Contract,\n",
    "                entertainment packs,\n",
    "                International Roaming Enquiry,\n",
    "                my vodafone family,\n",
    "                prepaid,\n",
    "                top up,\n",
    "                Account Query,\n",
    "                complaint,\n",
    "                Response,\n",
    "                Service,\n",
    "                buy back,\n",
    "                content control,\n",
    "                ivr,\n",
    "                live chat,\n",
    "                Locking/Unlocking,\n",
    "                My Vodacom app,\n",
    "                System: Down/Not Available,\n",
    "                USSD Enquiry,\n",
    "                Vodacom Online,\n",
    "                voicemail,\n",
    "                activation,\n",
    "                sim,\n",
    "                assistance & helpfulness,\n",
    "                Broken Arrangement,\n",
    "                call back,\n",
    "                Call Transferred,\n",
    "                communication,\n",
    "                Dropped Calls,\n",
    "                efficiency,\n",
    "                explanation,\n",
    "                friendliness & care,\n",
    "                hold,\n",
    "                inconsistency,\n",
    "                language,\n",
    "                listening,\n",
    "                misinformation,\n",
    "                politeness,\n",
    "                previous staff behavior,\n",
    "                professionalism,\n",
    "                Sales Enquiry,\n",
    "                staff behavior,\n",
    "                understanding,\n",
    "                Vodacom Shop,\n",
    "                wait time\n",
    "\n",
    "                If the text is not relevant to a topic from the list above, but another relevant topic is found, come up with a new topic and highlight it as a new topic.\n",
    "                \n",
    "                If no topic is found then respond with Topic as \"none\" and sentiment as the sentiment of the text.\n",
    "                \n",
    "                Respond with sentiment with options Positive/Negative/Neutral.\n",
    "\n",
    "                Here are a few examples of text and expected responses. Follow the format of responses mentioned in the examples:\n",
    "\n",
    "                Example 1:\n",
    "\n",
    "                Text: I like to go to my local Vodacom shop(Stillbay). Friendly people and helpfull. The call centre person on the other hand are a bit pushy, maybe the client can get SMS to state that there upgrade is due and then reply if they will visit a branch or if they want a agent giving them a call. Give us the choice.\n",
    "\n",
    "                Response\n",
    "                [\n",
    "                  {\n",
    "                    \"Topic\": \"Vodacom Shop\",\n",
    "                    \"Sentiment\": \"Positive\"\n",
    "                  },\n",
    "                  {\n",
    "                    \"Topic\": \"Customer Care enquiry\", \n",
    "                    \"Sentiment\": \"Negative\"\n",
    "                  },\n",
    "                  {\n",
    "                    \"Topic\": \"Upgrade Process\",\n",
    "                    \"Sentiment\": \"Neutral\",\n",
    "                    \"Note\": \"New\"\n",
    "                  }\n",
    "                ]\n",
    "\n",
    "                Example 2:\n",
    "                Text: Vodacom has become unaffordable on calls and data. Network also is a problem in many places\n",
    "                Response:\n",
    "                [\n",
    "                  {\n",
    "                    \"Topic\": \"Affordability\", \n",
    "                    \"Sentiment\": \"Negative\",\n",
    "                    \"Note\": \"New\"\n",
    "                  },\n",
    "                  {\n",
    "                    \"Topic\": \"General Network\",\n",
    "                    \"Sentiment\": \"Negative\"\n",
    "                  }\n",
    "                ]\n",
    "                \n",
    "                Example 3:\n",
    "                Text: No\n",
    "                Response:\n",
    "                [\n",
    "                  {\n",
    "                    \"Topic\": \"none\", \n",
    "                    \"Sentiment\": \"Neutral\"\n",
    "                  }\n",
    "                ]\n",
    "                \n",
    "                Example 4:\n",
    "                Text: Yes\n",
    "                Response:\n",
    "                [\n",
    "                  {\n",
    "                    \"Topic\": \"none\", \n",
    "                    \"Sentiment\": \"Neutral\"\n",
    "                  }\n",
    "                ]\n",
    "                \n",
    "                Example 5:\n",
    "                Text: All is well\n",
    "                Response:\n",
    "                [\n",
    "                  {\n",
    "                    \"Topic\": \"Customer's Feeling\", \n",
    "                    \"Sentiment\": \"Positive\"\n",
    "                  }\n",
    "                ]\n",
    "                \n",
    "                Example 6:\n",
    "                Text: Everything is bad\n",
    "                Response:\n",
    "                [\n",
    "                  {\n",
    "                    \"Topic\": \"Customer's Feeling\", \n",
    "                    \"Sentiment\": \"Negative\"\n",
    "                  }\n",
    "                ]\n",
    "\n",
    "                Assistant:\"\"\"\n",
    "    \n",
    "    body = json.dumps({\"prompt\": prompt,\n",
    "                 \"max_tokens_to_sample\":4096,\n",
    "                 \"temperature\":0.5,\n",
    "                 \"top_k\":250,\n",
    "                 \"top_p\":0.5,\n",
    "                 \"stop_sequences\":[]\n",
    "                  }) \n",
    "    return body\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06f167-6f9b-4f40-bc43-7ac4a2de2b1a",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e345f4-e8e6-45bd-9181-29037e39ad06",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac888f00-30ab-4aed-baa8-af11b4e11ac1",
   "metadata": {},
   "source": [
    "#### This function populates the result data frame in the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2876b75c-2f71-4f87-aa64-4fd41d151ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_df(dict_list, index, df, df_insights):\n",
    "            \n",
    "    row = df.iloc[index]\n",
    "    row_copy = row.copy()\n",
    "    #dict_list = json.loads(dict_list)\n",
    "    \n",
    "    for d in dict_list:\n",
    "        print(d)\n",
    "        # Use concat instead of append  \n",
    "        df_insights = pd.concat([df_insights, row_copy.to_frame().T], ignore_index=True)\n",
    "        \n",
    "         # Add new columns if needed\n",
    "        cols = ['Topic', 'Sentiment', 'Is_New_Topic']\n",
    "        for col in cols:\n",
    "            if col not in df_insights.columns:\n",
    "                df_insights[col] = \"\"\n",
    "            \n",
    "        df_insights.at[df_insights.index[-1], 'Topic'] = d.get('Topic')\n",
    "        df_insights.at[df_insights.index[-1], 'Sentiment'] = d.get('Sentiment')\n",
    "        df_insights.at[df_insights.index[-1], 'Is_New_Topic'] = d.get('Note') == 'New'\n",
    "\n",
    "    return df_insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3aa1b1-a571-4a13-8101-7396995deaab",
   "metadata": {},
   "source": [
    "#### This function finds and extracts the json from the LLM response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06dae24f-0983-40db-b453-ee997cabf7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def find_and_extract_json(text):\n",
    "    # Use regex to find text matching JSON structure\n",
    "    match = re.search(r'\\[.*?\\]', text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the matched JSON string \n",
    "        json_str = match.group(0)  \n",
    "        \n",
    "        try:\n",
    "            # Try loading it as JSON \n",
    "            data = json.loads(json_str)\n",
    "            return data\n",
    "        except json.JSONDecodeError:\n",
    "            # Was not valid JSON\n",
    "            return None\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b73198-8790-434c-97ea-cd4744a3100e",
   "metadata": {},
   "source": [
    "#### This function calls the Bedrock API to derive targetted sentiment against mentioned topics from the NPS verbatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a59f03d6-cb34-4158-aef8-fda3190f6434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_nps_verbatim_insights_fs(body,modelId, df, df_insights, index):\n",
    "    modelId = modelId # change this to use a different version from the model provider\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    \n",
    "    completion = response_body['completion']\n",
    "    \n",
    "    completion_json = find_and_extract_json(completion)\n",
    "\n",
    "    df_insights_upd = update_df(completion_json, index, df, df_insights)\n",
    "    \n",
    "    return df_insights_upd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27c1c5-0679-47c4-9b52-24f278b1ac5a",
   "metadata": {},
   "source": [
    "#### These lines of code iterate through the ingested NPS verbatim file, calls the nps insights extraction, and records the output\n",
    "\n",
    "> *This cell will take about 15min to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d30084-7751-46a3-86b0-cdba0e900ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_insights = pd.DataFrame()\n",
    "for index, row in df.iterrows():\n",
    "    if not pd.isnull(row['VERBATIM']):\n",
    "        raw_verbatim = row['VERBATIM']\n",
    "        print(raw_verbatim+\"\\n ********************************\\n\")\n",
    "        prompt = generate_prompt(raw_verbatim)\n",
    "        #print(prompt)\n",
    "        df_insights_upd = extract_nps_verbatim_insights_fs(prompt,'anthropic.claude-v2',df,df_insights,index)\n",
    "        df_insights = df_insights_upd\n",
    "        #print(f\"Row {index} : {nps_insight} \\n ********************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0368001-02c8-440d-bfe1-78951c6d067f",
   "metadata": {},
   "source": [
    "#### Explore the NPS insights output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97508633-2fc7-480e-9a35-4934af92e934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select columns to view\n",
    "columns = ['VERBATIM', 'Topic','Sentiment', 'Is_New_Topic']\n",
    "\n",
    "# View first 5 rows for selected columns\n",
    "print(df_insights_upd.loc[:100, columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130327a-be33-4b20-a782-dc0eee5cb8f8",
   "metadata": {},
   "source": [
    "#### Upload output nps insights file to S3\n",
    "⚠️ ⚠️ ⚠️ Please replace the below `bucket` and `key` variables below with the S3 bucket and prefix from your account where the jNPS sentiment analysis file should be stored ⚠️ ⚠️ ⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053437a-edcc-4700-b46b-024b5473f50a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S3 location\n",
    "bucket = 'vodacom-nps-poc-ajay'\n",
    "key = 'nps-insights/September2023/Buy_SetUp_insights.csv'\n",
    "\n",
    "# Write DataFrame to S3 in CSV format\n",
    "wr.s3.to_csv(\n",
    "    df=df_insights_upd,\n",
    "    path=f\"s3://{bucket}/{key}\", \n",
    "    index=False  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409b76c7-cbc5-4e35-bded-ad921f82d235",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You have now successfully used Amazon Bedrock to analyze NPS verbatims in the jNPS input file provided. Please go ahead and analyze the output using Amazon Quicksight's Generative BI.\n",
    "\n",
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "00878cbed564b904a98b4a19808853cb6b9988746b881ea025a8408713879bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
